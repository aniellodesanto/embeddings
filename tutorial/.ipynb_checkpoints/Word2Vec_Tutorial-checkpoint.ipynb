{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKA: A Quick Introduction to Word2Vec with Python and Gensim\n",
    "@Aniello De Santo, Feb 06, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up and getting some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a resource for our data\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using this in CoLab, also run this cell, otherwise you can skip it\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use the brown corpus\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by printing a few sentences out of the \"brown\" corpus, to get an idea of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_sent = brown.sents()\n",
    "print(brown_sent[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to build the whole model from scratch, we will use the Gensim library instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build an instance of the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the whole model for the brown corpus (it might take a few minutes)!\n",
    "brown_model = Word2Vec(brown_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = brown_model.wv.most_similar('blue')\n",
    "print(\"Most similar to 'blue':\\n\", test1[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refining the model\n",
    "\n",
    "Word2Vec takes a broad range of parameters. In our example above, we only chose where to get our sentences from, and we used the *default* settings for the rest. But let's now look at a few that are most relevant (you can find a full list here: https://radimrehurek.com/gensim/models/word2vec.html):\n",
    "\n",
    "- **size**: The dimensionality of our embeddings (i.e. the length of each word vector).\n",
    "- **window**: Which words are considered contexts of the target. The size of window affects the type of similarity captured in the embeddings.\n",
    "- **negative**: The number of negative samples (incorrect training-pair instances) that are drawn for each good.\n",
    "- **sg**: Training algorithm -- 1 for skip-gram; otherwise CBOW.\n",
    "- **min_count**: Ignores all words with total frequency lower than this.\n",
    "- **iter**: Number of iterations (epochs) over the corpus.\n",
    "\n",
    "So let's now train our model by explicitly setting some of these parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the whole model (it's going to take a few minutes!)\n",
    "brown_model = Word2Vec(brown_sent, size = 300, window = 5, negative = 5, sg = 1, min_count = 5, iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same test as before\n",
    "test = brown_model.wv.most_similar('blue')\n",
    "print(\"Most similar to 'blue':\\n\", test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to rely on our own **human intuitions** to decide how well the model is doing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = brown_model.wv.similarity(\"cup\", \"water\")\n",
    "print(\"How similar is 'cup' to 'water':\\n\", sim)\n",
    "\n",
    "sim = brown_model.wv.similarity(\"cup\", \"book\")\n",
    "print(\"How similar is 'cup' to 'book':\\n\", sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_test = brown_model.wv.most_similar('child')\n",
    "print(\"Most similar to 'child':\\n\", brown_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do more complex comparisons, but some results will be less intuitive than others!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_test = brown_model.wv.most_similar(positive = ['child'], negative = ['person'])\n",
    "print(\"Most similar to 'child' but dissimilar to 'person':\\n\", brown_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try a few more interesting tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which word is a mismatch in the sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch = brown_model.wv.doesnt_match(['teacher','professor','doctor','red','athlete','runner'])\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe not **just** semantic relations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch = brown_model.wv.doesnt_match(['running','swimming','singing','paper','reading','booking','catch'])\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = brown_model.wv.similarity('walk','walked') \n",
    "print(\"The similarity between 'walk' and 'walked':\\n\", compare)\n",
    "\n",
    "compare = brown_model.wv.similarity('look','looked') \n",
    "print(\"The similarity between 'look' and 'looked':\\n\", compare)\n",
    "\n",
    "compare = brown_model.wv.similarity('look','walk') \n",
    "print(\"The similarity between 'look' and 'walk':\\n\", compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The choice of training data\n",
    "\n",
    "As for the other parameters that we looked at, the **choice of training data** (our corpus) is essential in driving model performance.\n",
    "For example, consider a very famous test case for Word2Vec: is the model able to derive the fact that \"woman\" is to \"queen\" what \"man\" is to \"king\"?\n",
    "\n",
    "We can represent this question algebraically as:\n",
    "\n",
    "$$vector(woman) +  vector(king) - vector(man) = vector(queen)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = brown_model.wv.most_similar(positive=['woman','king'], negative=['man'], topn=1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a *weird* result!\n",
    "\n",
    "However, consider the fact that the brown corpus is not too big (1M words) and it is fairly old. What would happen if we used a bigger, more recent corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with a pretrained model\n",
    "\n",
    "Luckily, NLTK includes a pre-trained model which is part of a model that is trained on 100 billion words from the Google News Dataset. The full model is from https://code.google.com/p/word2vec/ (about 3 GB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to get the data\n",
    "from nltk.data import find\n",
    "nltk.download('word2vec_sample')\n",
    "\n",
    "# we are going to use a pruned set\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we are **not** training it from scratch, we are just loading it in (it is still going to take a bit)!\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"blue\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our example once more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['woman','king'], negative=['man'], topn = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(positive=['Paris','Germany'], negative=['Berlin'], topn = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do more! Let's track **semantic shifts** (e.g. historical changes in meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change1 = brown_model.wv.most_similar('gay')\n",
    "print(\"Most similar to 'gay' in the brown corpus:\\n\", change1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change2 = model.most_similar('gay')\n",
    "print(\"Most similar to 'gay' in Google News:\\n\", change2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relying on frequency patterns in human-generated data to make inferences has some problems..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare1 = model.similarity('she','engineer')\n",
    "print(\"The similarity between 'she' and 'engineer':\\n\", compare1)\n",
    "\n",
    "compare2 = model.similarity('he','engineer')\n",
    "print(\"The similarity between 'he' and 'engineer':\\n\", compare2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare1 = model.similarity('woman','nurse')\n",
    "print(\"The similarity between 'woman' and 'nurse':\\n\", compare1)\n",
    "\n",
    "compare2 = model.similarity('man','nurse')\n",
    "print(\"The similarity between 'man' and 'nurse':\\n\", compare2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare1 = model.similarity('black','criminal') \n",
    "print(\"The similarity between 'black' and 'criminal':\\n\", compare1)\n",
    "\n",
    "compare2 = model.similarity('white','criminal') \n",
    "print(\"The similarity between 'white' and 'criminal':\\n\", compare2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
